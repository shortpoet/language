{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pymongo\n",
    "from bson.json_util import dumps, loads\n",
    "from bson.objectid import ObjectId\n",
    "\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait # available since 2.4.0\n",
    "from selenium.webdriver.support import expected_conditions as EC # available since 2.26.0\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from pprint import pprint\n",
    "from datetime import datetime as dt\n",
    "import time\n",
    "import isodate\n",
    "\n",
    "import sys\n",
    "# sys.path.append('C:\\\\Users\\\\soria\\\\Documents\\\\WashUDataDocuments\\\\HwActivites\\\\YouTube_Project\\\\')\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': '/Users/soria/Anaconda3/Scripts/chromedriver'}\n",
    "# browser = Browser('chrome', **executable_path)\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.seriouseats.com/sitemap'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = driver.page_source\n",
    "se_sm_soup = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_recipe_links_dict = {}\n",
    "topic_anchors = se_sm_soup.find_all('a', href=re.compile('topics'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_recipe_links_dict['ingredient'] = []\n",
    "se_recipe_links_dict['method'] = []\n",
    "se_recipe_links_dict['meal'] = []\n",
    "se_recipe_links_dict['cuisine'] = []\n",
    "\n",
    "for i, anchor in enumerate(topic_anchors):\n",
    "#     print(f\"{i}: {anchor.text.strip()}\")\n",
    "#     print(anchor['href'])\n",
    "    link = anchor['href']\n",
    "    if 'ingredient' in link:\n",
    "        this_dict = {'topic': anchor.text.strip(), 'ingredient_url(s)': [link]}\n",
    "        se_recipe_links_dict['ingredient'].append(this_dict)\n",
    "    if 'method' in link:\n",
    "        this_dict = {'topic': anchor.text.strip(), 'method_url(s)': [link]}\n",
    "        se_recipe_links_dict['method'].append(this_dict)\n",
    "    if 'meal' in link:\n",
    "        this_dict = {'topic': anchor.text.strip(), 'meal_url(s)': [link]}\n",
    "        se_recipe_links_dict['meal'].append(this_dict)\n",
    "    if 'cuisine' in link:\n",
    "        this_dict = {'topic': anchor.text.strip(), 'cuisine_url(s)': [link]}\n",
    "        se_recipe_links_dict['cuisine'].append(this_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_recipe_links_dict['cuisine'] = se_recipe_links_dict['cuisine'][1:]\n",
    "se_recipe_links_dict['ingredient'] = se_recipe_links_dict['ingredient'][0:2] + se_recipe_links_dict['ingredient'][3:]\n",
    "se_recipe_links_dict['method'] = se_recipe_links_dict['method'][0:2] + se_recipe_links_dict['method'][3:]\n",
    "pprint(se_recipe_links_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def href_filt(href):\n",
    "    return re.compile('recipe').search(href) and re.compile('https').search(href) and not re.compile('topics').search(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {'cuisine': se_recipe_links_dict['cuisine']}\n",
    "for topic, _list in se_recipe_links_dict.items():\n",
    "    for _dict in _list:\n",
    "        _dict.setdefault('recipes', [])\n",
    "        string = topic + '_url(s)'\n",
    "        print(f\"string: {string}\")\n",
    "        for i, u in enumerate(_dict[string]):\n",
    "            cfTopic = re.sub(r'\\s', '_', _dict['topic'])\n",
    "            cfTopic = re.sub(r'/', '_', cfTopic)\n",
    "            print(cfTopic)\n",
    "            cacheFilePath = f\"C:\\\\Users\\\\soria\\\\Documents\\\\resources\\\\caches\\\\serious_eats_html_caches\\\\recipe_urls\\\\{cfTopic}_{i}.txt\"\n",
    "            print(f\"cfp: {cacheFilePath}\")\n",
    "            if os.path.isfile(cacheFilePath):\n",
    "                with open(cacheFilePath, encoding='utf-8') as cacheFile:\n",
    "                    html = cacheFile.read()\n",
    "                    se_recipe_soup = bs(html, 'html.parser')\n",
    "                    content = se_recipe_soup.find('div', class_='content-main')\n",
    "                    recipe_anchors = content.find_all('a', href=href_filt)\n",
    "                    for anchor in recipe_anchors[::2]:\n",
    "                        this_dict = {'recipe_title': anchor.text, 'recipe_url': anchor['href']}\n",
    "                        _dict['recipes'].append(this_dict)\n",
    "            else:\n",
    "                url = u\n",
    "                print(f\"url: {url}\")\n",
    "                time.sleep(random.uniform(0,3))\n",
    "                driver.get(url)\n",
    "                html = driver.page_source\n",
    "                with open(cacheFilePath, \"w\", encoding='utf-8') as cacheFile:\n",
    "                    cacheFile.write(html)        \n",
    "\n",
    "                se_recipe_soup = bs(html, 'html.parser')\n",
    "                content = se_recipe_soup.find('div', class_='content-main')\n",
    "                recipe_anchors = content.find_all('a', href=href_filt)\n",
    "                recipe_anchors = recipe_anchors[2:]\n",
    "                for anchor in recipe_anchors[::2]:\n",
    "                    this_dict = {'recipe_title': anchor.text, 'recipe_url': anchor['href']}\n",
    "                    _dict['recipes'].append(this_dict)\n",
    "                if se_recipe_soup.find('a', text=(re.compile('Next'))):\n",
    "                    time.sleep(random.uniform(0,5))\n",
    "                    url = se_recipe_soup.find('a', text=(re.compile('Next')))['href']\n",
    "                    _dict[string].append(url)\n",
    "                    driver.get(url)\n",
    "                    html = driver.page_source\n",
    "                    se_recipe_soup = bs(html, 'html.parser')\n",
    "                    content = se_recipe_soup.find('div', class_='content-main')\n",
    "                    recipe_anchors = content.find_all('a', href=href_filt)\n",
    "                    for anchor in recipe_anchors[::2]:\n",
    "                        this_dict = {'recipe_title': anchor.text, 'recipe_url': anchor['href']}\n",
    "                        _dict['recipes'].append(this_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(se_recipe_links_dict)\n",
    "# se_recipe_links_dict.keys()\n",
    "sys.getsizeof(se_recipe_links_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cacheFilePath = f\"C:\\\\Users\\\\soria\\\\Documents\\\\resources\\\\caches\\\\serious_eats_html_caches\\\\recipe_urls\"\n",
    "filess = []\n",
    "for root, dirs, files in os.walk(cacheFilePath):\n",
    "\n",
    "    for file in files:\n",
    "        filess.append(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, file in enumerate(filess):\n",
    "    print(f\"processing:{i} of {len(filess)}: {file}\")\n",
    "    for topic, _list in se_recipe_links_dict.items():\n",
    "        for _dict in _list:\n",
    "            _dict.setdefault('recipes', [])\n",
    "            cfTopic = re.sub(r'\\s', '_', _dict['topic'])\n",
    "            cfTopic = re.sub(r'/', '_', cfTopic)\n",
    "            if cfTopic in file:\n",
    "                cacheFilePath = f\"C:\\\\Users\\\\soria\\\\Documents\\\\resources\\\\caches\\\\serious_eats_html_caches\\\\recipe_urls\\\\{file}\"\n",
    "                with open(cacheFilePath, encoding='utf-8') as cacheFile:\n",
    "                    html = cacheFile.read()\n",
    "                    se_recipe_soup = bs(html, 'html.parser')\n",
    "                    content = se_recipe_soup.find('div', class_='content-main')\n",
    "                    recipe_anchors = content.find_all('a', href=href_filt)\n",
    "                    recipe_anchors = recipe_anchors[2:]\n",
    "                    for anchor in recipe_anchors[::2]:\n",
    "                        this_dict = {'recipe_title': anchor.text, 'recipe_url': anchor['href']}\n",
    "                        _dict['recipes'].append(this_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "mongoDb = client.serious_eats_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = mongoDb.se_recipe_just_url_test\n",
    "collection.insert_one(se_recipe_links_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = mongoDb.se_recipe_just_url_test\n",
    "url_dict = collection.find_one({}, {'_id':False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = mongoDb.se_recipe_just_url_test\n",
    "unupdated_dict = collection.find_one({}, {\"recipes.updated\":{'$exists': False}})\n",
    "unupdated_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic, topic_list in url_dict.items():\n",
    "    for index, subtopic_dict in enumerate(topic_list):\n",
    "        for _, _ in subtopic_dict.items():\n",
    "            for subindex, recipe_dict in enumerate(subtopic_dict['recipes']):\n",
    "                print(recipe_dict['recipe_title'])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.nested.findOne({\"level1\":{\"$elemMatch\":{\"$in\":['item00']}} })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab full list of recipe urls\n",
    "\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "mongoDb = client.serious_eats_test\n",
    "\n",
    "collection = mongoDb.se_recipe_just_url_test\n",
    "url_dict = collection.find_one({}, {'_id':False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new database with collection names spread out\n",
    "\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "mongoDb = client.serious_eats_test2\n",
    "\n",
    "for topic, topic_list in url_dict.items():\n",
    "    print(f'topic: {topic}')\n",
    "    for index, subtopic_dict in enumerate(topic_list):\n",
    "        collection = mongoDb[subtopic_dict['topic']]\n",
    "        collection.create_index('recipe_url', unique=True)\n",
    "        for _, _ in subtopic_dict.items():\n",
    "            for subindex, recipe_dict in enumerate(subtopic_dict['recipes']):\n",
    "                url = recipe['recipe_url']\n",
    "                print(f\"{topic}: {i} of {len(topic_dict['recipes'])} => {url}\")\n",
    "                title = recipe['recipe_title']\n",
    "                this_recipe = {\n",
    "                    'topic': subtopic_dict['topic'], 'source': 'serious_eats', \n",
    "                    'recipe_title': recipe['recipe_title'], 'recipe_url': recipe['recipe_url']\n",
    "                }\n",
    "                try:\n",
    "                    collection.insert_one(this_recipe)\n",
    "                except pymongo.errors.DuplicateKeyError:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list from collection names minus full url list collection\n",
    "\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "mongoDb = client.serious_eats_test2\n",
    "\n",
    "collection_names = mongoDb.list_collection_names()\n",
    "coll_names = []\n",
    "for i, coll in enumerate(collection_names):\n",
    "    print(i, coll)\n",
    "    coll_names.append(coll)\n",
    "\n",
    "coll_names = coll_names[:105] + coll_names[106:107]\n",
    "coll_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, coll in enumerate(coll_names):\n",
    "    print(i, coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set updated timestamp to url collection\n",
    "\n",
    "for topic, topic_list in url_dict.items():\n",
    "    for index, subtopic_dict in enumerate(topic_list):\n",
    "        for _, _ in subtopic_dict.items():\n",
    "            for subindex, recipe_dict in enumerate(subtopic_dict['recipes']):\n",
    "                this_url = recipe_dict['recipe_url']\n",
    "                mongoDb = client.serious_eats_test\n",
    "                collection = mongoDb[subtopic_dict['topic']]\n",
    "                if collection.find_one({'recipe_url':this_url}):\n",
    "#                     collection = mongoDb.se_recipe_just_url\n",
    "                    this_recipe = {\n",
    "                        'topic': subtopic_dict['topic'], 'source': 'serious_eats', \n",
    "                        'recipe_title': recipe_dict['recipe_title'],\n",
    "                        'recipe_url': recipe_dict['recipe_url'],\n",
    "                        'updated': dt.now()\n",
    "                    }\n",
    "                    this_query = f\"{subindex}\"\n",
    "                    print(f\"processing: {subtopic_dict['topic']} => {this_query}\")\n",
    "                    mongoDb = client.serious_eats_test2\n",
    "                    collection = mongoDb[subtopic_dict['topic']]\n",
    "                    collection.update_one({'recipe_url': this_url}, {\"$set\": this_recipe}, upsert=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of unupdated ids\n",
    "\n",
    "mongoDb = client.serious_eats_test2\n",
    "unupdated = {}\n",
    "for coll in coll_names:\n",
    "    collection = mongoDb[coll]\n",
    "    unupdated[coll] = []\n",
    "    r = collection.find({\"updated\":{'$exists': False}}, {})\n",
    "    for i in r:\n",
    "        unupdated[coll].append(i['_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unupdated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of unupdated recipe urls from ids\n",
    "\n",
    "\n",
    "unupdated_url_dict = {}\n",
    "for coll, obj_ids in unupdated.items():\n",
    "    collection = mongoDb[coll]\n",
    "    unupdated_url_dict[coll] = []\n",
    "    for _id in obj_ids:\n",
    "        r = collection.find_one({'_id': ObjectId(_id)})\n",
    "        print(f\"processing:{coll}{_id}\")\n",
    "        topic = r['topic']\n",
    "        url = r['recipe_url']\n",
    "        title = r['recipe_title']\n",
    "        this_dict = {'topic': topic, 'recipe_url': url, 'recipe_title': title}\n",
    "        unupdated_url_dict[coll].append(this_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coll, recipe_list in unupdated_url_dict.items():\n",
    "    collection = mongoDb[coll]\n",
    "    for recipe_dict in recipe_list:\n",
    "        recipe_dict.setdefault('recipes', [])\n",
    "        for i, u in enumerate(recipe_dict):\n",
    "            cfTopic = re.sub(r'\\s', '_', recipe_dict['topic'])\n",
    "            cfTopic = re.sub(r'/', '_', cfTopic)\n",
    "            print(cfTopic)\n",
    "            cacheFilePath = f\"C:\\\\Users\\\\soria\\\\Documents\\\\resources\\\\caches\\\\serious_eats_html_caches\\\\recipe_urls\\\\{cfTopic}_{i}.txt\"\n",
    "            print(f\"cfp: {cacheFilePath}\")\n",
    "            if os.path.isfile(cacheFilePath):\n",
    "                with open(cacheFilePath, encoding='utf-8') as cacheFile:\n",
    "                    html = cacheFile.read()\n",
    "                    se_recipe_soup = bs(html, 'html.parser')\n",
    "                    content = se_recipe_soup.find('div', class_='content-main')\n",
    "                    recipe_anchors = content.find_all('a', href=href_filt)\n",
    "                    for anchor in recipe_anchors[::2]:\n",
    "                        this_dict = {'recipe_title': anchor.text, 'recipe_url': anchor['href']}\n",
    "                        recipe_dict['recipes'].append(this_dict)\n",
    "                        collection.update_one({'recipe_url':recipe_dict['recipe_url']}, {'$set':{'recipes':anchor['href']}}, upsert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use if se_recipe_links_dict is created from scratch\n",
    "\n",
    "for topic, topic_list in url_dict.items():\n",
    "    print(f'topic: {topic}')\n",
    "    for topic_dict in topic_list:\n",
    "        collection = mongoDb[topic_dict['topic']]\n",
    "        collection.create_index('recipe_url', unique=True)\n",
    "        for i, recipe in enumerate(topic_dict['recipes']):\n",
    "            url = recipe['recipe_url']\n",
    "            print(f\"{topic}: {i} of {len(topic_dict['recipes'])} => {url}\")\n",
    "            cfTitle = re.sub(r\"\\s|/|\\.|,|'|-|\\?|\\||<|>|\\\\|\\*|:\", '_', recipe['recipe_title'])\n",
    "            cfTitle = re.sub(r'\"', '', cfTitle)\n",
    "            cfTitle = re.sub(r'__', '_', cfTitle)\n",
    "            if cfTitle[0:1] == \"_\":\n",
    "                cfTitle = cfTitle[1:]\n",
    "            if cfTitle[-1:] == \"_\":\n",
    "                cfTitle = cfTitle[:-1]\n",
    "            cfTitle = cfTitle[:32]\n",
    "            print(f\"cfTitle: {cfTitle}\")\n",
    "            cacheFilePath = f\"C:\\\\Users\\\\soria\\\\Documents\\\\resources\\\\caches\\\\serious_eats_html_caches\\\\{cfTitle}.txt\"\n",
    "            print(f\"cfp: {cacheFilePath}\")\n",
    "            \n",
    "            if os.path.isfile(cacheFilePath):\n",
    "                with open(cacheFilePath, encoding='utf-8') as cacheFile:\n",
    "                    html = cacheFile.read()\n",
    "            else:\n",
    "                driver.get(url)\n",
    "                html = driver.page_source          \n",
    "                with open(cacheFilePath, 'w', encoding='utf-8') as cacheFile:\n",
    "                    cacheFile.write(html)\n",
    "            se_soup = bs(html, 'html.parser')\n",
    "            script_divs = se_soup.find_all('script', {'type': 'application/ld+json'})\n",
    "#             recipe['category_trees'] = []\n",
    "#             recipe['recipe'] = []\n",
    "            category_trees = []\n",
    "            for index, div in enumerate(script_divs):\n",
    "                try:\n",
    "                    j = json.loads(div.text, strict=False)\n",
    "\n",
    "                    recipe.setdefault('category_trees', [])\n",
    "                    recipe.setdefault('recipe', {})\n",
    "\n",
    "                    if j['@type'] == 'BreadcrumbList':\n",
    "                        category_tree = []\n",
    "                        for item in j['itemListElement']:\n",
    "                            category_tree.append(item['item']['name'])\n",
    "    #                     recipe['category_trees'].append(category_tree)\n",
    "                        category_trees.append(category_tree)\n",
    "\n",
    "                    if j['@type'] == 'Recipe':\n",
    "                        try:\n",
    "                            rating_count = j['aggregateRating']['ratingCount']\n",
    "                        except:\n",
    "                            rating_count = False\n",
    "                        try:\n",
    "                            rating_value = j['aggregateRating']['ratingValue']\n",
    "                        except:\n",
    "                            rating_value = False\n",
    "                        try:\n",
    "                            author = j['author']['name']\n",
    "                        except:\n",
    "                            author = False\n",
    "                        try:\n",
    "                            job_title = j['author']['jobTitle']\n",
    "                        except:\n",
    "                            job_title = False\n",
    "                        try:\n",
    "                            description = j['description']\n",
    "                        except:\n",
    "                            description = False\n",
    "                        try:\n",
    "                            keywords = j['keywords']\n",
    "                        except:\n",
    "                            keywords = False\n",
    "                        try: \n",
    "                            name = j['name']\n",
    "                        except:\n",
    "                            name = False\n",
    "                        try:\n",
    "                            categories = j['recipeCategory']\n",
    "                        except:\n",
    "                            categories = False\n",
    "                        try:\n",
    "                            cuisine = j['recipeCuisine']\n",
    "                        except:\n",
    "                            cuisine = False\n",
    "                        try:\n",
    "                            ingredients = j['recipeIngredient']\n",
    "                        except:\n",
    "                            ingredients = False\n",
    "                        try:   \n",
    "                            steps = {}\n",
    "                            for i, step in enumerate(j['recipeInstructions']):\n",
    "                                this = 'step_' + str(i+1)\n",
    "                                steps[this] = step['text']\n",
    "                        except:\n",
    "                            steps = False\n",
    "                        try:\n",
    "                            recipe_yield = j['recipeYield']\n",
    "                        except:\n",
    "                            recipe_yield = False\n",
    "                        try:\n",
    "                            time = str(isodate.parse_duration(j['totalTime']).total_seconds()/60)\n",
    "                        except:\n",
    "                            time = False\n",
    "    #                     recipe['recipe'] = {\n",
    "                        json_recipe = {\n",
    "                            'name': name, 'rating_count': rating_count, 'rating_value': rating_value, 'author': author,\n",
    "                            'job_title': job_title, 'description': description, 'keywords': keywords, 'categories': categories,\n",
    "                            'cuisine': cuisine, 'ingredients': ingredients, 'steps': steps, 'recipe_yield': recipe_yield, 'time':time\n",
    "                        }\n",
    "                except:\n",
    "                    print(f\"json error on:{url} - script_div{index}\")\n",
    "                    continue\n",
    "            this_recipe = {\n",
    "                'topic': topic_dict['topic'], 'source': 'serious_eats', \n",
    "                'recipe_title': recipe['recipe_title'], 'recipe_url': recipe['recipe_url'], \n",
    "#                 'category_trees': recipe['category_trees'], 'recipe': recipe['recipe'], \n",
    "                'category_trees': recipe['category_trees'], 'recipe': json_recipe, \n",
    "                'uploaded': dt.now()\n",
    "            }\n",
    "            try:\n",
    "                collection.insert_one(this_recipe)\n",
    "            except pymongo.errors.DuplicateKeyError:\n",
    "                continue\n",
    "#             collection.update_one({}, {'$set': collection.this_recipe}, upsert=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfTitle = re.sub(r\"\\s|/|\\.|,|'|-\", '_', 'C:\\\\Users\\\\soria\\\\Documents\\\\resources\\\\caches\\\\serious_eats_html_caches\\\\Weeknight_Turkey_\"Bolognese\".txt')\n",
    "cfTitle = re.sub(r'\"', '', cfTitle)\n",
    "cfTitle = re.sub(r'__', '_', cfTitle)\n",
    "cfTitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "mongoDb = client.serious_eats_test_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se_recipe_links_dict.pop('_id')\n",
    "for topic, _list in se_recipe_links_dict.items():\n",
    "    collection = mongoDb[topic]\n",
    "    collection.insert_many(_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use if pulled from mongo\n",
    "\n",
    "for topic, topic_dict in se_recipe_links_dict.items():\n",
    "    print(f'topic: {topic}')\n",
    "    for i, recipe in enumerate(topic_dict['recipes']):\n",
    "        url = recipe['recipe_url']\n",
    "        print(f\"{topic}: {i} of {len(topic_dict['recipes'])} => {url}\")\n",
    "        driver.get(url)\n",
    "        html = driver.page_source\n",
    "        se_soup = bs(html, 'html.parser')\n",
    "        script_divs = se_soup.find_all('script', {'type': 'application/ld+json'})\n",
    "        for div in script_divs:\n",
    "            j = json.loads(div.text, strict=False)\n",
    "\n",
    "            recipe.setdefault('category_trees', [])\n",
    "            recipe.setdefault('recipe', {})\n",
    "\n",
    "            if j['@type'] == 'BreadcrumbList':\n",
    "                category_tree = []\n",
    "                for item in j['itemListElement']:\n",
    "                    category_tree.append(item['item']['name'])\n",
    "                recipe['category_trees'].append(category_tree)\n",
    "            if j['@type'] == 'Recipe':\n",
    "                try:\n",
    "                    rating_count = j['aggregateRating']['ratingCount']\n",
    "                except:\n",
    "                    rating_count = False\n",
    "                try:\n",
    "                    rating_value = j['aggregateRating']['ratingValue']\n",
    "                except:\n",
    "                    rating_value = False\n",
    "                try:\n",
    "                    author = j['author']['name']\n",
    "                except:\n",
    "                    author = False\n",
    "                try:\n",
    "                    job_title = j['author']['jobTitle']\n",
    "                except:\n",
    "                    job_title = False\n",
    "                try:\n",
    "                    description = j['description']\n",
    "                except:\n",
    "                    description = False\n",
    "                try:\n",
    "                    keywords = j['keywords']\n",
    "                except:\n",
    "                    keywords = False\n",
    "                try: \n",
    "                    name = j['name']\n",
    "                except:\n",
    "                    name = False\n",
    "                try:\n",
    "                    categories = j['recipeCategory']\n",
    "                except:\n",
    "                    categories = False\n",
    "                try:\n",
    "                    cuisine = j['recipeCuisine']\n",
    "                except:\n",
    "                    cuisine = False\n",
    "                try:\n",
    "                    ingredients = j['recipeIngredient']\n",
    "                except:\n",
    "                    ingredients = False\n",
    "                try:   \n",
    "                    steps = {}\n",
    "                    for i, step in enumerate(j['recipeInstructions']):\n",
    "                        this = 'step_' + str(i+1)\n",
    "                        steps[this] = step['text']\n",
    "                except:\n",
    "                    steps = False\n",
    "                try:\n",
    "                    recipe_yield = j['recipeYield']\n",
    "                except:\n",
    "                    recipe_yield = False\n",
    "                try:\n",
    "                    time = str(isodate.parse_duration(j['totalTime']).total_seconds()/60)\n",
    "                except:\n",
    "                    time = False\n",
    "                recipe['recipe'] = {\n",
    "                    'name': name, 'rating_count': rating_count, 'rating_value': rating_value, 'author': author,\n",
    "                    'job_title': job_title, 'description': description, 'keywords': keywords, 'categories': categories,\n",
    "                    'cuisine': cuisine, 'ingredients': ingredients, 'steps': steps, 'recipe_yield': recipe_yield, 'time':time\n",
    "                }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use for unupdated dict\n",
    "\n",
    "mongoDb = client.serious_eats_test\n",
    "\n",
    "for coll, recipe_list in unupdated_url_dict.items():\n",
    "    \n",
    "    collection = mongoDb[coll]\n",
    "    collection.create_index('recipe_url', unique=True)\n",
    "    for i, recipe_dict in enumerate(recipe_list):\n",
    "        url = recipe_dict['recipe_url']\n",
    "        print(f\"{coll}: {i} of {len(recipe_list)} => {url}\")\n",
    "        cfTitle = re.sub(r\"\\s|/|\\.|,|'|-|\\?|\\||<|>|\\\\|\\*|:\", '_', recipe_dict['recipe_title'])\n",
    "        cfTitle = re.sub(r'\"', '', cfTitle)\n",
    "        cfTitle = re.sub(r'__', '_', cfTitle)\n",
    "        if cfTitle[0:1] == \"_\":\n",
    "            cfTitle = cfTitle[1:]\n",
    "        if cfTitle[-1:] == \"_\":\n",
    "            cfTitle = cfTitle[:-1]\n",
    "        cfTitle = cfTitle[:32]\n",
    "        print(f\"cfTitle: {cfTitle}\")\n",
    "        cacheFilePath = f\"C:\\\\Users\\\\soria\\\\Documents\\\\resources\\\\caches\\\\serious_eats_html_caches\\\\{cfTitle}.txt\"\n",
    "        print(f\"cfp: {cacheFilePath}\")\n",
    "\n",
    "        if os.path.isfile(cacheFilePath):\n",
    "            with open(cacheFilePath, encoding='utf-8') as cacheFile:\n",
    "                html = cacheFile.read()\n",
    "        else:\n",
    "            driver.get(url)\n",
    "            wait = WebDriverWait(driver, 10)\n",
    "            wait.until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//script[@type='application/ld+json']\")))\n",
    "            html = driver.page_source          \n",
    "            with open(cacheFilePath, 'w', encoding='utf-8') as cacheFile:\n",
    "                cacheFile.write(html)\n",
    "        se_soup = bs(html, 'html.parser')\n",
    "        script_divs = se_soup.find_all('script', {'type': 'application/ld+json'})\n",
    "#             recipe_dict['category_trees'] = []\n",
    "#             recipe_dict['recipe'] = []\n",
    "        category_trees = []\n",
    "        for index, div in enumerate(script_divs):\n",
    "            try:\n",
    "                j = json.loads(div.text, strict=False)\n",
    "\n",
    "                recipe_dict.setdefault('category_trees', [])\n",
    "                recipe_dict.setdefault('recipe', {})\n",
    "\n",
    "                if j['@type'] == 'BreadcrumbList':\n",
    "                    category_tree = []\n",
    "                    for item in j['itemListElement']:\n",
    "                        category_tree.append(item['item']['name'])\n",
    "    #                     recipe_dict['category_trees'].append(category_tree)\n",
    "                    category_trees.append(category_tree)\n",
    "\n",
    "                if j['@type'] == 'Recipe':\n",
    "                    try:\n",
    "                        rating_count = j['aggregateRating']['ratingCount']\n",
    "                    except:\n",
    "                        rating_count = False\n",
    "                    try:\n",
    "                        rating_value = j['aggregateRating']['ratingValue']\n",
    "                    except:\n",
    "                        rating_value = False\n",
    "                    try:\n",
    "                        author = j['author']['name']\n",
    "                    except:\n",
    "                        author = False\n",
    "                    try:\n",
    "                        job_title = j['author']['jobTitle']\n",
    "                    except:\n",
    "                        job_title = False\n",
    "                    try:\n",
    "                        description = j['description']\n",
    "                    except:\n",
    "                        description = False\n",
    "                    try:\n",
    "                        keywords = j['keywords']\n",
    "                    except:\n",
    "                        keywords = False\n",
    "                    try: \n",
    "                        name = j['name']\n",
    "                    except:\n",
    "                        name = False\n",
    "                    try:\n",
    "                        categories = j['recipeCategory']\n",
    "                    except:\n",
    "                        categories = False\n",
    "                    try:\n",
    "                        cuisine = j['recipeCuisine']\n",
    "                    except:\n",
    "                        cuisine = False\n",
    "                    try:\n",
    "                        ingredients = j['recipeIngredient']\n",
    "                    except:\n",
    "                        ingredients = False\n",
    "                    try:   \n",
    "                        steps = {}\n",
    "                        for i, step in enumerate(j['recipeInstructions']):\n",
    "                            this = 'step_' + str(i+1)\n",
    "                            steps[this] = step['text']\n",
    "                    except:\n",
    "                        steps = False\n",
    "                    try:\n",
    "                        recipe_yield = j['recipeYield']\n",
    "                    except:\n",
    "                        recipe_yield = False\n",
    "                    try:\n",
    "                        time = str(isodate.parse_duration(j['totalTime']).total_seconds()/60)\n",
    "                    except:\n",
    "                        time = False\n",
    "    #                     recipe_dict['recipe'] = {\n",
    "                    json_recipe = {\n",
    "                        'name': name, 'rating_count': rating_count, 'rating_value': rating_value, 'author': author,\n",
    "                        'job_title': job_title, 'description': description, 'keywords': keywords, 'categories': categories,\n",
    "                        'cuisine': cuisine, 'ingredients': ingredients, 'steps': steps, 'recipe_yield': recipe_yield, 'time':time\n",
    "                    }\n",
    "            except ValueError:\n",
    "                print('==================')\n",
    "                print(f\"      json error on:{url} - script_div{index}\")\n",
    "                print('==================')\n",
    "                json_recipe = ''\n",
    "                continue\n",
    "        this_recipe = {\n",
    "            'topic': recipe_dict['topic'], 'source': 'serious_eats', \n",
    "            'recipe_title': recipe_dict['recipe_title'], 'recipe_url': recipe_dict['recipe_url'], \n",
    "#                 'category_trees': recipe_dict['category_trees'], 'recipe': recipe_dict['recipe'], \n",
    "            'category_trees': category_trees, 'recipe': json_recipe, \n",
    "            'uploaded': dt.now()\n",
    "        }\n",
    "        try:\n",
    "            collection.insert_one(this_recipe)\n",
    "        except pymongo.errors.DuplicateKeyError:\n",
    "            continue\n",
    "#             collection.update_one({}, {'$set': collection.this_recipe}, upsert=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
